{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_text = \"\"\"Doctor: How are you Miss G? \n",
    "Patient: I am good doctor, thank you for asking. \n",
    "Doctor: So, tell me what is going on?\n",
    "Patient: I have this ear pain and headache for some time. It's better than before but I still want to get it checked. \n",
    "Doctor: Okay, when exactly did it start?\n",
    "Patient: Um, almost three weeks ago. I am having difficulty hearing. I also feel this pressure on the left side of my sinus causing tooth pain. I went to my dentist yesterday, but my teeth are fine. \n",
    "Doctor: Okay, do you have headache now?\n",
    "Patient: No, just ear pain and this jaw pain on the left side. \n",
    "Doctor: Any fever, cough, sore throat, or any cold like symptoms? \n",
    "Patient: No, but I have a sinus problem and I suffer from chronic left sided headache.\n",
    "Doctor: How old are you?\n",
    "Patient: Oh, I am forty nine.\n",
    "Doctor: Hm, so are you taking any medications for your pain?\n",
    "Patient: No, currently I am just using Cutivate for my eczema. It has helped me a lot, I do need a refill for it. \n",
    "Doctor: Okay I will send a prescription for it to your pharmacy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invain/.virtualenvs/spacy/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/invain/.virtualenvs/spacy/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/invain/.virtualenvs/spacy/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(dialog_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miss G PERSON\n",
      "almost three weeks ago DATE\n",
      "yesterday DATE\n",
      "Cutivate PRODUCT\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"Patient: I just had few questions. Can you tell me about my diagnosis?\n",
    "Doctor: Sure. It's called Serotonin syndrome, ma'am. After careful evaluation of your labs, we found out that your white count and C P K was high, and those abnormalities lined up with serotonin syndrome. What are you experiencing right now?\n",
    "Patient: I have been very restless and easily agitated, I have diarrhea. But no fever or shakiness.\n",
    "Doctor: These can match serotonin syndrome as well. You deny any fever, tremor or hypperflexia so we will give you some IV fluids and I will check on you in an hour or so.\n",
    "Patient: Okay. \n",
    "Doctor: Looks like your C P K counts improved with I V fluids and after discontinuing Prozac.\n",
    "Patient: How are the counts now? Are they normal? Because I feel normal.\n",
    "Doctor: Yes, your C P K and white blood cell counts have come back down. Almost normal now.\n",
    "Patient: My husband left me two weeks ago. My panic attacks are increasing day by day.\n",
    "Doctor: Okay, I see that you have a history of panic attacks and you do have depression and anxiety, is that correct? Last Friday, I talked to psychiatrist about your issues, and he recommended Cymbalta as an alternative to Prozac. \n",
    "Patient: Yes, I stopped taking Prozac, and I am going to see him on Monday or Tuesday. I have a counselor too.\n",
    "Patient: I do think it will be difficult to go home alone but my daughter is coming to visit me in two weeks.\n",
    "Doctor: Oh wow.\n",
    "Patient: Yeah.\n",
    "Doctor: That's nice. Do you have someone who can drop you home and help you?\n",
    "Patient: Yes, I have a friend who does that, I am staying with her for next three days.\n",
    "Doctor: Okay that sounds good. Just continue with your medications for high blood pressure and diabetes as well. So, we treated your imbalance issues and gave you IV fluids, you do not have any more diarrhea, right?\n",
    "Patient: Yes, that's right.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default model identified 0 entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy\n",
    "nlp = medspacy.load( )\n",
    "doc2 = nlp(text2)\n",
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## medical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_sci_scibert\n",
    "import en_core_med7_trf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IV ROUTE\n",
      "fluids DRUG\n",
      "fluids DRUG\n",
      "Prozac DRUG\n",
      "Cymbalta DRUG\n",
      "Prozac DRUG\n",
      "Prozac DRUG\n",
      "IV ROUTE\n",
      "fluids DRUG\n"
     ]
    }
   ],
   "source": [
    "# import scispacy\n",
    "import spacy\n",
    "\n",
    "nlp2 = spacy.load(\"en_core_med7_trf\")\n",
    "doc2 = nlp2(text2)\n",
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(IV, fluids, fluids, Prozac, Cymbalta, Prozac, Prozac, IV, fluids)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent recognitioin / classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent recognized: greeting\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to recognize intent\n",
    "def recognize_intent(text):\n",
    "    doc = nlp(text)\n",
    "    # Here you can define your intents based on the entities or patterns\n",
    "    intents = {'greeting': ['hello', 'hi', 'hey'], 'goodbye': ['bye', 'goodbye']}\n",
    "    for token in doc:\n",
    "        for intent, keywords in intents.items():\n",
    "            if token.text.lower() in keywords:\n",
    "                return intent\n",
    "    return 'unknown'\n",
    "\n",
    "# Example usage\n",
    "user_input = 'Hello, how are you?'\n",
    "intent = recognize_intent(user_input)\n",
    "print(f'Intent recognized: {intent}')  # Output: Intent recognized: greeting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = [\n",
    "#     ('Hello, I need help', {'entities': [(0, 5, 'greeting')]}),\n",
    "#     ('Goodbye, see you later', {'entities': [(0, 7, 'goodbye')]}),\n",
    "# ]\n",
    "training_data = [\n",
    "    ('Hello, I need help', {'cats': {'greeting': 1.0, 'goodbye': 0.0}}),\n",
    "    ('How is it going', {'cats': {'greeting': 1.0, 'goodbye': 0.0}}),\n",
    "    ('Goodbye, see you later', {'cats': {'greeting': 0.0, 'goodbye': 1.0}}),\n",
    "    ('Byebye, see you', {'cats': {'greeting': 0.0, 'goodbye': 1.0}}),\n",
    "    ('see you', {'cats': {'greeting': 0.0, 'goodbye': 1.0}}),\n",
    "    ('Hi there', {'cats': {'greeting': 1.0, 'goodbye': 0.0}}),\n",
    "    ('See you soon', {'cats': {'greeting': 0.0, 'goodbye': 1.0}}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "# text_cat = nlp.create_pipe('textcat')\n",
    "text_cat = nlp.add_pipe('textcat', last=True)\n",
    "text_cat.add_label('greeting')\n",
    "text_cat.add_label('goodbye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 0.25}\n",
      "{'textcat': 0.2427244335412979}\n",
      "{'textcat': 0.23560336232185364}\n",
      "{'textcat': 0.2227870374917984}\n",
      "{'textcat': 0.21068832278251648}\n",
      "{'textcat': 0.18657274544239044}\n",
      "{'textcat': 0.18335475027561188}\n",
      "{'textcat': 0.18716123700141907}\n",
      "{'textcat': 0.1483396738767624}\n",
      "{'textcat': 0.11363311111927032}\n",
      "{'textcat': 0.11102795600891113}\n",
      "{'textcat': 0.09083671122789383}\n",
      "{'textcat': 0.08976726979017258}\n",
      "{'textcat': 0.04922223836183548}\n",
      "{'textcat': 0.062485165894031525}\n",
      "{'textcat': 0.030504679307341576}\n",
      "{'textcat': 0.024628501385450363}\n",
      "{'textcat': 0.01169653795659542}\n",
      "{'textcat': 0.01180785708129406}\n",
      "{'textcat': 0.008775681257247925}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "examples = []\n",
    "for text, annots in training_data:\n",
    "    examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "nlp.initialize(lambda: examples)\n",
    "\n",
    "n_iter = 20\n",
    "for epoch in range(n_iter):\n",
    "    random.shuffle(examples)\n",
    "    losses = {}\n",
    "    # Create the minibatch generator\n",
    "    for batch in minibatch(examples, size=8):\n",
    "        nlp.update(batch, drop=0.3, losses=losses)\n",
    "    print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing: 'Hello there'\n",
      "Prediction scores:\n",
      "greeting: 0.9404430389404297\n",
      "goodbye: 0.059556975960731506\n",
      "Predicted category: greeting\n",
      "\n",
      "Analyzing: 'Goodbye'\n",
      "Prediction scores:\n",
      "greeting: 0.07562782615423203\n",
      "goodbye: 0.924372136592865\n",
      "Predicted category: goodbye\n",
      "\n",
      "Analyzing: 'See you later'\n",
      "Prediction scores:\n",
      "greeting: 0.013240814208984375\n",
      "goodbye: 0.9867592453956604\n",
      "Predicted category: goodbye\n"
     ]
    }
   ],
   "source": [
    "# Assuming trained_nlp is your trained model\n",
    "def predict_text_category(nlp, text):\n",
    "    doc = nlp(text)\n",
    "    print(\"Prediction scores:\")\n",
    "    for label, score in doc.cats.items():\n",
    "        print(f\"{label}: {score}\")\n",
    "    \n",
    "    # Get the category with the highest score\n",
    "    predicted_category = max(doc.cats, key=doc.cats.get)\n",
    "    print(f\"Predicted category: {predicted_category}\")\n",
    "    return predicted_category\n",
    "\n",
    "# Example usage\n",
    "test_texts = [\n",
    "    \"Hello there\",\n",
    "    \"Goodbye\",\n",
    "    \"See you later\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"\\nAnalyzing: '{text}'\")\n",
    "    predict_text_category(nlp, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule based solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/invain/.virtualenvs/spacy/lib/python3.12/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.7.1) was trained with spaCy v3.7.2 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/invain/.virtualenvs/spacy/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/invain/.virtualenvs/spacy/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/invain/.virtualenvs/spacy/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {\"LOWER\": {\"IN\": [\"print\", \"generate\", \"create\"]}},  # Action keywords\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"*\"},  # Allow intermediate words\n",
    "    {\"LOWER\": \"map\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"*\"},  # Allow intermediate words\n",
    "    {\"LOWER\": {\"IN\": [\"hospital\", \"clinic\", \"station\"]}}  # Target keywords\n",
    "]\n",
    "matcher.add(\"PRINT_MAP\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "can you print a map for the Toronto hospital I was wondering if we could generate one for the Guelph clinic what about printing directions to the nearest gas station\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9095104806068616893 3 10\n",
      "Matched Intent: print a map for the Toronto hospital\n",
      "Descriptor:  hospital\n",
      "9095104806068616893 3 22\n",
      "Matched Intent: print a map for the Toronto hospital I was wondering if we could generate one for the Guelph clinic\n",
      "Descriptor:  hospital\n",
      "Descriptor:  clinic\n",
      "9095104806068616893 3 31\n",
      "Matched Intent: print a map for the Toronto hospital I was wondering if we could generate one for the Guelph clinic what about printing directions to the nearest gas station\n",
      "Descriptor:  hospital\n",
      "Descriptor:  clinic\n",
      "Descriptor:  station\n"
     ]
    }
   ],
   "source": [
    "for matchid, start, end in matches:\n",
    "    print(matchid, start, end)\n",
    "    span = doc[start:end]\n",
    "    print(f\"Matched Intent: {span.text}\")\n",
    "    for token in span:\n",
    "        if token.text.lower() in [\"hospital\", \"clinic\", \"station\"]:\n",
    "            # Check for location descriptors\n",
    "            descriptor = \" \".join(child.text for child in token.lefts if child.dep in [\"compound\", \"amod\"])\n",
    "            print(f\"Descriptor: {descriptor} {token.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freescribe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
